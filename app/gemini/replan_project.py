import google.generativeai as genai
import json
from datetime import datetime
from app.gemini.json_to_markdown import json_to_markdown

def replan_project_with_gemini(original_json: dict, chat_history: list[dict]) -> dict:
    cleaned_json = {
        "projects": original_json.get("projects", [])
    }
    
    chat_text = "\n".join([
        f"{item['sender'].upper()}: {item['message']}" for item in chat_history
    ])

    prompt = f"""
ä½ æ˜¯ä¸€å€‹å°ˆæ¡ˆåŠ©ç†ï¼Œæ ¹æ“šä¸‹æ–¹åŸå§‹å°ˆæ¡ˆè¦åŠƒ JSON èˆ‡ä½¿ç”¨è€…çš„å®Œæ•´å›é¥‹ç´€éŒ„ï¼Œè«‹é‡æ–°ç”¢å‡ºå°ˆæ¡ˆè¦åŠƒã€‚

## æ ¼å¼ï¼š
è«‹ç”¢å‡ºç¬¦åˆä»¥ä¸‹ JSON çµæ§‹çš„å…§å®¹ï¼ˆä¿æŒæ¬„ä½åç¨±èˆ‡çµæ§‹ï¼‰ï¼š
{{
  "projects": [
  {{
    "name": "...",
    "summary": "...",
    "start_time": "...",
    "end_time": "...",
    "due_date": "...",
    "estimated_loading": ...,
    "current_milestone": "...",
    "milestones": [
    {{
      "name": "...",
      "summary": "...",
      "start_time": "...",
      "end_time": "...",
      "estimated_loading": ...,
      "tasks": [
      {{
        "title": "...",
        "description": "...",
        "due_date": "...",
        "estimated_loading": ...,
        "is_completed": false
      }}
      ]
    }}
    ]
  }}
  ]
}}

## èª¿æ•´è¦å‰‡ï¼š
è«‹éµå®ˆä»¥ä¸‹è¦å‰‡ï¼š
1. æ‰€æœ‰æ—¥æœŸèˆ‡æ™‚é–“æ¬„ä½ï¼ˆstart_time, end_time, due_dateï¼‰å‡éœ€å¡«å¯«ï¼Œä¸å¾—ç‚º nullã€‚
2. æ‰€æœ‰ estimated_loading è«‹çµ¦å‡ºåˆç†æ•´æ•¸ä¼°ç®—ï¼ˆä¾‹å¦‚ 5, 10, 20ï¼‰ï¼Œä¸å¾—å‡ºç¾ % çš„åœ–æ¡ˆï¼Œä¹Ÿä¸å¾—ç‚º nullã€‚
3. current_milestone è«‹å‹™å¿…å¡«å¯« milestone é™£åˆ—è£¡é¢ç¬¬ä¸€å€‹ milestone çš„ 'name'ï¼Œä¸å¾—ç‚º nullã€‚
4. æ¯å€‹ Milestone è‡³å°‘æ‹†è§£å‡º 3 é …å…·é«”ä»»å‹™ï¼ˆtasksï¼‰ã€‚
5. ä»»å‹™å‘½åèˆ‡å…§å®¹æ‡‰æ ¹æ“šé‡Œç¨‹ç¢‘æ‘˜è¦åˆç†æ‹†è§£ï¼Œé¿å…éæ–¼æ¨¡ç³Šæˆ–é‡è¤‡ã€‚
6. æ¯å€‹ä»»å‹™çš„ due_date è«‹æ ¹æ“šé‚è¼¯å…ˆå¾Œé †åºèˆ‡å·¥æ™‚æ¨è«–ï¼Œåˆç†åˆ†é…è‡³ milestone çµæŸæ—¥å‰ã€‚
7. Milestone çš„ estimated_loading ä¸å¯æ¯”åº•ä¸‹æ‰€æœ‰ä»»å‹™çš„ estimated_loading ç¸½å’Œå¤šè¶…é 10 å°æ™‚ã€‚
8. estimated_loading å·¥æ™‚ä¼°ç®—è«‹ä¾ä»»å‹™é¡å‹çµ¦äºˆåˆç†ç¯„åœï¼Œå…·é«”å¦‚ä¸‹ï¼š
   - æ–‡æ›¸è™•ç†é¡ä»»å‹™ï¼ˆå¦‚å ±å‘Šæ’°å¯«ã€è³‡æ–™å½™æ•´ã€æœƒè­°è¨˜éŒ„ç­‰ï¼‰é€šå¸¸ä»‹æ–¼ 5ï½10 å°æ™‚
   - ç¨‹å¼é–‹ç™¼é¡ä»»å‹™ï¼ˆå¦‚æ’°å¯« APIã€è³‡æ–™åº«è¨­è¨ˆã€å‰ç«¯å¯¦ä½œç­‰ï¼‰é€šå¸¸ä»‹æ–¼ 20ï½60 å°æ™‚
9. è«‹å…ˆä¸è¦è®“ project çš„ç¸½ estimated_loading è¶…é 100 å°æ™‚ï¼Œæœ€å¤šåˆ° 99 å°æ™‚ã€‚
10. è«‹åƒ…å›å‚³ç¬¦åˆæ ¼å¼çš„ç´” JSON çµæœï¼Œä¸éœ€é¡å¤–èªªæ˜æˆ–è¨»è§£ã€‚

## åŸå§‹å°ˆæ¡ˆå…§å®¹ï¼š
{json.dumps(cleaned_json, ensure_ascii=False, indent=2)}

## ä½¿ç”¨è€…å°è©±ç´€éŒ„ï¼š
{chat_text}

## è«‹ç›´æ¥è¼¸å‡ºç¬¦åˆæ ¼å¼çš„ JSON çµæœï¼Œä¸éœ€é¡å¤–èªªæ˜æˆ–è¨»è§£ã€‚
"""

    model = genai.GenerativeModel("gemini-1.5-flash", generation_config=genai.types.GenerationConfig(temperature=0.2,top_p=0.9))
    
    try:
        response = model.generate_content(prompt)
        if not response.text or not response.text.strip():
            print("âš ï¸ Gemini å›å‚³ç©ºå…§å®¹")
            print("ğŸ§ª Prompt Preview:\n", prompt[:1000])
            raise ValueError("Gemini å›å‚³ç©ºå…§å®¹ï¼Œè«‹æª¢æŸ¥ prompt æ˜¯å¦å¤ªé•·æˆ–æ ¼å¼æœ‰èª¤ã€‚")
        
        raw = response.text.strip().replace("```json", "").replace("```", "")
        updated_json = json.loads(raw)

        return updated_json

    except Exception as e:
        print("ğŸ”¥ Gemini raw response:")
        print(response.text if response else "ï¼ˆNoneï¼‰")
        raise e